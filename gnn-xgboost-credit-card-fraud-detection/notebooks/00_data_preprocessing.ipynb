{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da8a963d-13ed-4555-a452-254f3901e55b",
   "metadata": {},
   "source": [
    "# IBM Credit Card Transcation Data \n",
    "\n",
    "- Download the dataset from [here](https://ibm.ent.box.com/v/tabformer-data/folder/130747715605), untar and uncompress the file ( ``` tar -xvzf ./transactions.tgz ```) and place the file in the \"./data/TabFormer/raw\" folder.\n",
    "\n",
    "- This dataset contains 24M records with 15 fields, one field being the \"is fraud\" label which we use for training. \n",
    "\n",
    "## Goals \n",
    "\n",
    "The goal is to:\n",
    "\n",
    "- Cleanup the data\n",
    "    - Make field names just single word\n",
    "        -while field names are not used within the GNN, it makes accessing fields easier during cleanup\n",
    "    - Encode categorical fields\n",
    "        - use one-hot encoding for fields with less than 8 categories\n",
    "        - use binary encoding for fields with more than 8 categories\n",
    "    - Create a continuous node index across users, merchants, and transactions\n",
    "        - Having node ID start at zero and then be contiguous is critical for creation of Compressed Sparse Row (CSR) formatted data without wasting memory.\n",
    "- Produce:\n",
    "    - For XGBoost:\n",
    "        - Training - all data before 2018\n",
    "        - Validation - all data during 2018\n",
    "        - Test. - all data after 2018\n",
    "    - For GNN\n",
    "        - Training Data\n",
    "            - Edge List\n",
    "            - Feature data\n",
    "        - Test set - all data after 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4248f0-a9a4-499c-bd59-c216b16ef879",
   "metadata": {},
   "source": [
    "# Installing Dependencies\n",
    "\n",
    "- Create a dependencies.yaml file by copying the dependencies from the YAML file [here](https://github.com/nv-morpheus/morpheus-experimental/blob/branch-25.02/ai-credit-fraud-workflow/conda/fraud_conda_env.yaml).\n",
    "- Install Conda and run the following commands in the terminal:\n",
    "    - ``` conda install conda-forge::mamba ```\n",
    "    - ``` mamba env create -f dependencies.yaml ```\n",
    "    - ``` conda activate fraud_conda_env ```\n",
    "- Install the Jupyter kernel for the fraud_conda_env using the following command:\n",
    "    - ``` python -m ipykernel install --user --name=fraud_conda_env --display-name \"Python (fraud_conda_env)\" ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70341bf9-850e-497f-826d-7d346866c956",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the necessary libraries. In this case will be use cuDF and perform most of the data prep in GPU\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import cudf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as ss\n",
    "from category_encoders import BinaryEncoder\n",
    "from scipy.stats import pointbiserialr\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "312c9516-cf58-4755-9746-0ca09b7738e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define arguments\n",
    "\n",
    "# Whether the graph is undirected\n",
    "make_undirected = True\n",
    "\n",
    "# Whether to spread features across Users and Merchants nodes\n",
    "spread_features = False\n",
    "\n",
    "# Whether we should under-sample majority class (i.e. non-fraud transactions)\n",
    "under_sample = True\n",
    "\n",
    "# Ration of fraud and non-fraud transactions in case we under-sample the majority class\n",
    "fraud_ratio = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e4c20a4-7501-49b5-8fe0-0e9169b34fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabformer_base_path = 'data/TabFormer'\n",
    "tabformer_raw_file_path = os.path.join(tabformer_base_path, 'raw', 'card_transaction.v1.csv')\n",
    "tabformer_xgb = os.path.join(tabformer_base_path, 'xgb')\n",
    "tabformer_gnn = os.path.join(tabformer_base_path, 'gnn')\n",
    "\n",
    "if not os.path.exists(tabformer_xgb):\n",
    "    os.makedirs(tabformer_xgb)\n",
    "if not os.path.exists(tabformer_gnn):\n",
    "    os.makedirs(tabformer_gnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3975e008-f912-4453-985f-9d119fdc8044",
   "metadata": {},
   "source": [
    "## Load and Understand the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "314727fb-7a02-4725-96c1-ae40b4669ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "data = cudf.read_csv(tabformer_raw_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43f86326-b36d-4f10-a8e4-0d667522c921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Card</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Time</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Use Chip</th>\n",
       "      <th>Merchant Name</th>\n",
       "      <th>Merchant City</th>\n",
       "      <th>Merchant State</th>\n",
       "      <th>Zip</th>\n",
       "      <th>MCC</th>\n",
       "      <th>Errors?</th>\n",
       "      <th>Is Fraud?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2002</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>06:21</td>\n",
       "      <td>$134.09</td>\n",
       "      <td>Swipe Transaction</td>\n",
       "      <td>3527213246127876953</td>\n",
       "      <td>La Verne</td>\n",
       "      <td>CA</td>\n",
       "      <td>91750.0</td>\n",
       "      <td>5300</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2002</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>06:42</td>\n",
       "      <td>$38.48</td>\n",
       "      <td>Swipe Transaction</td>\n",
       "      <td>-727612092139916043</td>\n",
       "      <td>Monterey Park</td>\n",
       "      <td>CA</td>\n",
       "      <td>91754.0</td>\n",
       "      <td>5411</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2002</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>06:22</td>\n",
       "      <td>$120.34</td>\n",
       "      <td>Swipe Transaction</td>\n",
       "      <td>-727612092139916043</td>\n",
       "      <td>Monterey Park</td>\n",
       "      <td>CA</td>\n",
       "      <td>91754.0</td>\n",
       "      <td>5411</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2002</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>17:45</td>\n",
       "      <td>$128.95</td>\n",
       "      <td>Swipe Transaction</td>\n",
       "      <td>3414527459579106770</td>\n",
       "      <td>Monterey Park</td>\n",
       "      <td>CA</td>\n",
       "      <td>91754.0</td>\n",
       "      <td>5651</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2002</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>06:23</td>\n",
       "      <td>$104.71</td>\n",
       "      <td>Swipe Transaction</td>\n",
       "      <td>5817218446178736267</td>\n",
       "      <td>La Verne</td>\n",
       "      <td>CA</td>\n",
       "      <td>91750.0</td>\n",
       "      <td>5912</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User  Card  Year  Month  Day   Time   Amount           Use Chip  \\\n",
       "0     0     0  2002      9    1  06:21  $134.09  Swipe Transaction   \n",
       "1     0     0  2002      9    1  06:42   $38.48  Swipe Transaction   \n",
       "2     0     0  2002      9    2  06:22  $120.34  Swipe Transaction   \n",
       "3     0     0  2002      9    2  17:45  $128.95  Swipe Transaction   \n",
       "4     0     0  2002      9    3  06:23  $104.71  Swipe Transaction   \n",
       "\n",
       "         Merchant Name  Merchant City Merchant State      Zip   MCC Errors?  \\\n",
       "0  3527213246127876953       La Verne             CA  91750.0  5300    <NA>   \n",
       "1  -727612092139916043  Monterey Park             CA  91754.0  5411    <NA>   \n",
       "2  -727612092139916043  Monterey Park             CA  91754.0  5411    <NA>   \n",
       "3  3414527459579106770  Monterey Park             CA  91754.0  5651    <NA>   \n",
       "4  5817218446178736267       La Verne             CA  91750.0  5912    <NA>   \n",
       "\n",
       "  Is Fraud?  \n",
       "0        No  \n",
       "1        No  \n",
       "2        No  \n",
       "3        No  \n",
       "4        No  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optional - take a look at the data \n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "326c7c7e-f0e3-46df-9213-b72059219252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['User', 'Card', 'Year', 'Month', 'Day', 'Time', 'Amount', 'Use Chip',\n",
       "       'Merchant Name', 'Merchant City', 'Merchant State', 'Zip', 'MCC',\n",
       "       'Errors?', 'Is Fraud?'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f43cf4c-922d-40c1-a1a7-1ac9db346041",
   "metadata": {},
   "source": [
    "### Findings\n",
    "\n",
    "- Ordinal categorical fields - 'Year', 'Month', 'Day'\n",
    "- Nominal categorical fields - 'User', 'Card', 'Merchant Name', 'Merchant City', 'Merchant State', 'Zip', 'MCC', 'Errors?'\n",
    "- Target label - 'Is Fraud?'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98117c86-cb11-4eff-a0c1-a74959a18e57",
   "metadata": {},
   "source": [
    "## Check if are there Null values in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb428633-a2da-4486-b18e-026ed7081c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User                     0\n",
       "Card                     0\n",
       "Year                     0\n",
       "Month                    0\n",
       "Day                      0\n",
       "Time                     0\n",
       "Amount                   0\n",
       "Use Chip                 0\n",
       "Merchant Name            0\n",
       "Merchant City            0\n",
       "Merchant State     2720821\n",
       "Zip                2878135\n",
       "MCC                      0\n",
       "Errors?           23998469\n",
       "Is Fraud?                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check which fields are missing values\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45caf67b-01f6-4971-9662-a38dddc53b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User               0.000000\n",
       "Card               0.000000\n",
       "Year               0.000000\n",
       "Month              0.000000\n",
       "Day                0.000000\n",
       "Time               0.000000\n",
       "Amount             0.000000\n",
       "Use Chip           0.000000\n",
       "Merchant Name      0.000000\n",
       "Merchant City      0.000000\n",
       "Merchant State    11.156896\n",
       "Zip               11.801972\n",
       "MCC                0.000000\n",
       "Errors?           98.407215\n",
       "Is Fraud?          0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check percentage of missing values\n",
    "100*data.isnull().sum()/len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5434aecc-a2f0-42ee-a2b3-44b617856048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a few raw transactions for model's inference notebook\n",
    "out_path = os.path.join(tabformer_xgb, 'example_transactions.csv')\n",
    "data.tail(10).to_pandas().to_csv(out_path, header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0008b5e7-f193-4c6f-9716-0c48fc999932",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's rename the column names to single words and use variables for column names to make access easier\n",
    "COL_USER = 'User'\n",
    "COL_CARD = 'Card'\n",
    "COL_AMOUNT = 'Amount'\n",
    "COL_MCC = 'MCC'\n",
    "COL_TIME = 'Time'\n",
    "COL_DAY = 'Day'\n",
    "COL_MONTH = 'Month'\n",
    "COL_YEAR = 'Year'\n",
    "\n",
    "COL_MERCHANT = 'Merchant'\n",
    "COL_STATE ='State'\n",
    "COL_CITY ='City'\n",
    "COL_ZIP = 'Zip'\n",
    "COL_ERROR = 'Errors'\n",
    "COL_CHIP = 'Chip'\n",
    "COL_FRAUD = 'Fraud'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "86122cd8-3947-46eb-9826-7f8ffb39ef7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = data.rename(columns={\n",
    "    \"Merchant Name\": COL_MERCHANT,\n",
    "    \"Merchant State\": COL_STATE,\n",
    "    \"Merchant City\": COL_CITY,\n",
    "    \"Errors?\": COL_ERROR,\n",
    "    \"Use Chip\": COL_CHIP,\n",
    "    \"Is Fraud?\": COL_FRAUD\n",
    "    },\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fde4cd0-9025-4bd5-b0fe-6282adb12283",
   "metadata": {},
   "source": [
    "## Handling Missing Values\n",
    "- Zip codes are numeral, replace missing zip codes by 0\n",
    "- State and Error are string, replace missing values by marker 'XX'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8783cd97-f011-4a9b-b512-c6cd04053194",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNKNOWN_STRING_MARKER = 'XX'\n",
    "UNKNOWN_ZIP_CODE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "650b6f23-20cc-42f6-be1a-c03467141496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that 'XX' doesn't exist in State and Error field before we replace missing values by 'XX'\n",
    "assert(UNKNOWN_STRING_MARKER not in set(data[COL_STATE].unique().to_pandas()))\n",
    "assert(UNKNOWN_STRING_MARKER not in set(data[COL_ERROR].unique().to_pandas()))\n",
    "\n",
    "# Make sure that 0 or 0.0 doesn't exist in Zip field before we replace missing values by 0\n",
    "assert(float(0) not in set(data[COL_ZIP].unique().to_pandas()))\n",
    "assert(0 not in set(data[COL_ZIP].unique().to_pandas()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7985413-450c-4cbc-8ce3-81120bab7dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values with markers\n",
    "data[COL_STATE] = data[COL_STATE].fillna(UNKNOWN_STRING_MARKER)\n",
    "data[COL_ERROR] = data[COL_ERROR].fillna(UNKNOWN_STRING_MARKER)\n",
    "data[COL_ZIP] = data[COL_ZIP].fillna(UNKNOWN_ZIP_CODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dee4a256-713f-44b5-83a5-c5745512b121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There shouldn't be any missing values in the data now.\n",
    "assert(data.isnull().sum().sum() == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0194391-1491-40e9-83be-e8fc807491c1",
   "metadata": {},
   "source": [
    "## Clean up the Amount field\n",
    "\n",
    "- Drop the \"$\" from the Amount field and then convert from string to float\n",
    "- Look into spread of Amount and choose right scaler for it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb696094-3c45-4f5f-a211-cb68e5e7e582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the \"$\" from the Amount field and then convert from string to float \n",
    "data[COL_AMOUNT] = data[COL_AMOUNT].str.replace(\"$\",\"\").astype(\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9866cb1e-e629-40bf-b429-79f4bdbea81b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2.438690e+07\n",
       "mean     4.363401e+01\n",
       "std      8.202239e+01\n",
       "min     -5.000000e+02\n",
       "25%      9.200000e+00\n",
       "50%      3.014000e+01\n",
       "75%      6.506000e+01\n",
       "max      1.239050e+04\n",
       "Name: Amount, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[COL_AMOUNT].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d88921ac-8d18-4436-af30-2af119137ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    29757.000000\n",
       "mean       108.590874\n",
       "std        201.167421\n",
       "min       -500.000000\n",
       "25%         18.360000\n",
       "50%         71.020000\n",
       "75%        150.130000\n",
       "max       5694.440000\n",
       "Name: Amount, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's look into how the Amount differ between fraud and non-fraud transactions\n",
    "# Fraud transactions\n",
    "data[COL_AMOUNT][data[COL_FRAUD]=='Yes'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3821c784-2a24-4007-850b-33f50bef7e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2.435714e+07\n",
       "mean     4.355465e+01\n",
       "std      8.173917e+01\n",
       "min     -5.000000e+02\n",
       "25%      9.200000e+00\n",
       "50%      3.011000e+01\n",
       "75%      6.500000e+01\n",
       "max      1.239050e+04\n",
       "Name: Amount, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Non-fraud transactions\n",
    "data[COL_AMOUNT][data[COL_FRAUD]=='No'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517b1e8b-6fed-4325-b0bd-dbafff29782b",
   "metadata": {},
   "source": [
    "### Findings\n",
    "\n",
    "- 25th percentile of non-fraud transactions = 9.2\n",
    "- 75th percentile of non-fraud transactions = 65\n",
    "- Median is around 30 and the mean is around 43 whereas the max value is over 1200 and min value is -500\n",
    "- Average amount in Fraud transactions > 2x the average amount in Non-Fraud transactions.\n",
    "\n",
    "We need to scale the data, and **RobustScaler** could be a good choice for it as it uses the median and IQR (Interquartile Range) to scale without being heavily influenced by these outliers.\n",
    "\n",
    "You can use other scalers depending on your data. For example, if your data is approximately normally distributed, you can use **StandardScaler**, and if it’s in a specific range, you can use **MinMaxScaler**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef6c157-fee5-4712-9a14-67c4a667b1d0",
   "metadata": {},
   "source": [
    "## 'Fraud' Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6438e5a4-72ed-440f-ae91-af30e27ce355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     No\n",
       "1    Yes\n",
       "Name: Fraud, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many different categories are there in the COL_FRAUD column?\n",
    "# The hope is that there are only two categories, 'Yes' and 'No'\n",
    "data[COL_FRAUD].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4453a012-5549-4ebc-98a6-a7cbe55bf4b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fraud\n",
       "No     24357143\n",
       "Yes       29757\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[COL_FRAUD].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "638985f7-fb96-46bb-a74d-6f72dd8e8a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fraud\n",
       "No     99.87798\n",
       "Yes     0.12202\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * data[COL_FRAUD].value_counts()/len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "64c28495-8440-4dab-a4cc-d1944ba3541d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the 'Fraud' values to be integere where 1==Fraud and 0==Non-fraud\n",
    "fraud_to_binary = {'No': 0, 'Yes': 1}\n",
    "data[COL_FRAUD] = data[COL_FRAUD].map(fraud_to_binary).astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8f58dafa-eca9-49b3-9bb1-e7597f0127c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fraud\n",
       "0    24357143\n",
       "1       29757\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[COL_FRAUD].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29260aa0-45ce-4ebb-93da-169ae9993701",
   "metadata": {},
   "source": [
    "##  'City', 'State', and 'Zip' columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e880355b-9485-492c-9e52-f05d0e69c513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               La Verne\n",
       "1          Monterey Park\n",
       "2                 ONLINE\n",
       "3              Mira Loma\n",
       "4            Diamond Bar\n",
       "              ...       \n",
       "13424          Loysville\n",
       "13425    Laurel Bloomery\n",
       "13426            Alburgh\n",
       "13427            Buskirk\n",
       "13428             Mooers\n",
       "Name: City, Length: 13429, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# City\n",
    "data[COL_CITY].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dc0dc583-795e-49c8-8b1e-59b9f704ded5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                            CA\n",
       "1                            XX\n",
       "2                            NE\n",
       "3                            IL\n",
       "4                            MO\n",
       "                 ...           \n",
       "219    Central African Republic\n",
       "220                       Qatar\n",
       "221    East Timor (Timor-Leste)\n",
       "222                  Seychelles\n",
       "223                     Andorra\n",
       "Name: State, Length: 224, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# State\n",
    "data[COL_STATE].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "216f97dc-0416-40d5-b5cf-d78419471a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        91750.0\n",
       "1        91754.0\n",
       "2        91755.0\n",
       "3            0.0\n",
       "4        91752.0\n",
       "          ...   \n",
       "27317    17047.0\n",
       "27318    37680.0\n",
       "27319     5440.0\n",
       "27320    12028.0\n",
       "27321    12958.0\n",
       "Name: Zip, Length: 27322, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Zip\n",
    "data[COL_ZIP].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0332ceb-949e-4dd5-a040-309ca41acc91",
   "metadata": {},
   "source": [
    "##  'Chip' column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8b29d02f-6107-441f-bd2d-11da9170b06f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Swipe Transaction\n",
       "1    Online Transaction\n",
       "2      Chip Transaction\n",
       "Name: Chip, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[COL_CHIP].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a2694e-5dd9-4a4f-9918-6c3d938dfc48",
   "metadata": {},
   "source": [
    "## 'Error' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "93d56954-3cea-4ae2-94ad-61a3f36720f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                    XX\n",
       "1                                     Technical Glitch,\n",
       "2                                 Insufficient Balance,\n",
       "3                                              Bad PIN,\n",
       "4                         Bad PIN,Insufficient Balance,\n",
       "5                                       Bad Expiration,\n",
       "6                             Bad PIN,Technical Glitch,\n",
       "7                                      Bad Card Number,\n",
       "8                                              Bad CVV,\n",
       "9                                          Bad Zipcode,\n",
       "10               Insufficient Balance,Technical Glitch,\n",
       "11                Bad Card Number,Insufficient Balance,\n",
       "12                             Bad Card Number,Bad CVV,\n",
       "13                        Bad CVV,Insufficient Balance,\n",
       "14                      Bad Card Number,Bad Expiration,\n",
       "15                              Bad Expiration,Bad CVV,\n",
       "16                 Bad Expiration,Insufficient Balance,\n",
       "17                     Bad Expiration,Technical Glitch,\n",
       "18     Bad Card Number,Bad Expiration,Technical Glitch,\n",
       "19                            Bad CVV,Technical Glitch,\n",
       "20                    Bad Card Number,Technical Glitch,\n",
       "21                    Bad Zipcode,Insufficient Balance,\n",
       "22                        Bad Zipcode,Technical Glitch,\n",
       "23    Bad Card Number,Bad Expiration,Insufficient Ba...\n",
       "Name: Errors, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[COL_ERROR].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2924a9eb-97c4-4811-adb6-90a4ec7ad92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove ',' in error descriptions\n",
    "data[COL_ERROR] = data[COL_ERROR].str.replace(\",\",\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e7a62f-393e-495c-a360-70b74cfc70ad",
   "metadata": {},
   "source": [
    "### Findings\n",
    "We can one hot or binary encode columns with fewer categories and binary/hash encode columns with more than 8 categories\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c41616-6f75-4e04-a879-74c1986031d7",
   "metadata": {},
   "source": [
    "## Time\n",
    "Time is captured as hour:minute.\n",
    "\n",
    "We are converting the time to just be the number of minutes.\n",
    "time = (hour * 60) + minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "539b3af9-53f4-4100-ae4e-144b69d77037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     24386900\n",
       "unique        1440\n",
       "top          12:31\n",
       "freq         30604\n",
       "Name: Time, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[COL_TIME].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e87b0017-bb0a-4a3a-b92c-5c9c8ac821c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the time column into hours and minutes and then cast to int32\n",
    "T = data[COL_TIME].str.split(':', expand=True)\n",
    "T[0] = T[0].astype('int32')\n",
    "T[1] = T[1].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7779b3d6-2a9a-4b1b-bdd1-1dd786d3b503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the 'Time' column with the new columns\n",
    "data[COL_TIME] = (T[0] * 60 ) + T[1]\n",
    "data[COL_TIME] = data[COL_TIME].astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ec74d6c1-6b91-45c5-84b2-f887eef64614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete temporary DataFrame\n",
    "del(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba08fe40-d2bf-408d-8705-565ea82b18cf",
   "metadata": {},
   "source": [
    "## Merchant Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5edc0416-94fc-4fcd-b26d-98610e97241e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           3527213246127876953\n",
       "1           -727612092139916043\n",
       "2           -727612092139916043\n",
       "3           3414527459579106770\n",
       "4           5817218446178736267\n",
       "                   ...         \n",
       "24386895   -5162038175624867091\n",
       "24386896   -5162038175624867091\n",
       "24386897    2500998799892805156\n",
       "24386898    2500998799892805156\n",
       "24386899    4751695835751691036\n",
       "Name: Merchant, Length: 24386900, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[COL_MERCHANT] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fa3e35d8-15dd-4418-89e1-acc554326d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          3527213246127876953\n",
       "1          -727612092139916043\n",
       "2          3414527459579106770\n",
       "3          5817218446178736267\n",
       "4         -7146670748125200898\n",
       "                  ...         \n",
       "100338     2963633013590132543\n",
       "100339     3970346884766028008\n",
       "100340    -4348891722741102135\n",
       "100341     -642409450154660123\n",
       "100342    -3533580464561517260\n",
       "Name: Merchant, Length: 100343, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the column to str type\n",
    "data[COL_MERCHANT] = data[COL_MERCHANT].astype('str')\n",
    "\n",
    "# Over 100,000 merchants\n",
    "data[COL_MERCHANT].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022c0cf0-1266-4f1d-bc91-7d0720f4280b",
   "metadata": {},
   "source": [
    "## The Card column\n",
    "- \"Card 0\" for User 1 is different from \"Card 0\" for User 2.\n",
    "- Combine User and Card in a way such that (User, Card) combination is unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "91b4e3e5-7dcb-41a1-9058-53d77992f8bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    2\n",
       "3    3\n",
       "4    4\n",
       "5    5\n",
       "6    6\n",
       "7    7\n",
       "8    8\n",
       "Name: Card, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[COL_CARD].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "929badea-d3cb-4b6b-b290-9ae055871d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_nr_cards_per_user = len(data[COL_CARD].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2bf8ee3d-bd0d-47fa-a831-0c6bed4fb8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine User and Card to generate unique numbers\n",
    "data[COL_CARD] = data[COL_USER] * len(data[COL_CARD].unique())  + data[COL_CARD]\n",
    "data[COL_CARD] = data[COL_CARD].astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f110f4c-ee4f-42fb-964c-492be3a367a3",
   "metadata": {},
   "source": [
    "## Correlation of different categorical fields with target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "85a3a116-a13d-4ac6-8910-2c0593cfa311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://en.wikipedia.org/wiki/Cram%C3%A9r's_V\n",
    "\n",
    "def cramers_v(x, y):\n",
    "    confusion_matrix = cudf.crosstab(x, y).to_numpy()\n",
    "    chi2 = ss.chi2_contingency(confusion_matrix)[0]\n",
    "    n = confusion_matrix.sum().sum()\n",
    "    r, k = confusion_matrix.shape\n",
    "    return np.sqrt(chi2 / (n * (min(k-1, r-1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6c85a914-4a36-4b67-a57f-7bb2291ab2ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation (Card, Fraud) =   6.59%\n",
      "Correlation (Chip, Fraud) =   5.63%\n",
      "Correlation (Errors, Fraud) =   1.81%\n",
      "Correlation (State, Fraud) =  35.92%\n",
      "Correlation (City, Fraud) =  32.47%\n",
      "Correlation (Zip, Fraud) =  14.99%\n",
      "Correlation (MCC, Fraud) =  12.70%\n",
      "Correlation (Merchant, Fraud) =  34.88%\n",
      "Correlation (User, Fraud) =   3.40%\n",
      "Correlation (Day, Fraud) =   0.26%\n",
      "Correlation (Month, Fraud) =   0.23%\n",
      "Correlation (Year, Fraud) =   2.35%\n"
     ]
    }
   ],
   "source": [
    "sparse_factor = 1\n",
    "columns_to_compute_corr =  [COL_CARD, COL_CHIP, COL_ERROR, COL_STATE, COL_CITY, COL_ZIP, COL_MCC, COL_MERCHANT, COL_USER, COL_DAY, COL_MONTH, COL_YEAR]\n",
    "for c1 in columns_to_compute_corr:\n",
    "    for c2 in [COL_FRAUD]:\n",
    "        coff =  100 * cramers_v(data[c1][::sparse_factor], data[c2][::sparse_factor])\n",
    "        print('Correlation ({}, {}) = {:6.2f}%'.format(c1, c2, coff))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78684231-77e7-42a6-94d0-15408cff7520",
   "metadata": {},
   "source": [
    "## Correlation of different numerical columns with target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5ca1c6ea-3804-44dd-bd80-420fa62e1284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r_pb (Time) = -0.00 with p_value 0.00\n",
      "r_pb (Amount) = 0.03 with p_value 0.00\n"
     ]
    }
   ],
   "source": [
    "# https://en.wikipedia.org/wiki/Point-biserial_correlation_coefficient\n",
    "# Use Point-biserial correlation coefficient(rpb) to check if the numerical columns are important to predict if a transaction is fraud\n",
    "\n",
    "\n",
    "for col in [COL_TIME, COL_AMOUNT]:\n",
    "    r_pb, p_value = pointbiserialr(data[COL_FRAUD].to_pandas(), data[col].to_pandas())\n",
    "    print('r_pb ({}) = {:3.2f} with p_value {:3.2f}'.format(col,  r_pb, p_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30f9195-2875-468b-9041-e924f6d2166f",
   "metadata": {},
   "source": [
    "### Findings\n",
    "- Clearly, Time is not an important predictor\n",
    "- Amount has 3% correlation with target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4995d77b-4a7d-459d-9a9c-060e9b42a98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Based on correlation, select a set of columns (aka fields) to predict whether a transaction is fraud\n",
    "# As the cross correlation of Fraud with Day, Month, Year is significantly lower,\n",
    "# we can skip them for now and add these features later.\n",
    "\n",
    "numerical_predictors = [COL_AMOUNT]\n",
    "nominal_predictors = [COL_ERROR, COL_CARD, COL_CHIP, COL_CITY, COL_ZIP, COL_MCC, COL_MERCHANT]\n",
    "\n",
    "predictor_columns = numerical_predictors + nominal_predictors\n",
    "\n",
    "target_column = [COL_FRAUD]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fc32cf-a13e-4c3c-8200-723d280311d3",
   "metadata": {},
   "source": [
    "## Remove duplicates non-fraud data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0bbd562a-ef35-46a2-a46d-08f69d5c2539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates data points\n",
    "fraud_data = data[data[COL_FRAUD] == 1]\n",
    "data = data[data[COL_FRAUD] == 0]\n",
    "data = data.drop_duplicates(subset=nominal_predictors)\n",
    "data = cudf.concat([data, fraud_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8172862b-6548-45e0-907c-52722a186cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fraud\n",
       "0    98.378669\n",
       "1     1.621331\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percentage of fraud and non-fraud cases\n",
    "100*data[COL_FRAUD].value_counts()/len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0953c29-704b-47dd-8340-eb1bc84d7c14",
   "metadata": {},
   "source": [
    "## Split the data into\n",
    "The data will be split into thee groups based on event date\n",
    "\n",
    "- Training - all data before 2018\n",
    "- Validation - all data during 2018\n",
    "- Test. - all data after 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b89d0645-c28d-48de-87cc-06640a7a9b4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fraud\n",
       "0    297570\n",
       "1     29757\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if under_sample:    \n",
    "    fraud_df = data[data[COL_FRAUD]==1]\n",
    "    non_fraud_df = data[data[COL_FRAUD]==0]\n",
    "    nr_non_fraud_samples = min((len(data) - len(fraud_df)), int(len(fraud_df)/fraud_ratio))\n",
    "    data = cudf.concat([fraud_df, non_fraud_df.sample(nr_non_fraud_samples)])\n",
    "\n",
    "training_idx = data[COL_YEAR] < 2018\n",
    "validation_idx = data[COL_YEAR] == 2018\n",
    "test_idx = data[COL_YEAR] > 2018\n",
    "\n",
    "data[COL_FRAUD].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb0ce94-f021-48d9-89aa-375d0ef4818c",
   "metadata": {},
   "source": [
    "## Scale numerical columns and encode categorical columns of training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7e6937ce-2045-484a-a1e0-099ce35b6f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As some of the encoder we want to use is not available in cuml, we can use pandas for now.\n",
    "# Move training data to pandas for preprocessing\n",
    "pdf_training = data[training_idx].to_pandas()[predictor_columns + target_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "aca92169-31a6-455c-ba88-8db0674839b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors 23\n",
      "Card 6065\n",
      "Chip 3\n",
      "City 11279\n",
      "Zip 22658\n",
      "MCC 109\n",
      "Merchant 45152\n"
     ]
    }
   ],
   "source": [
    "#Use one-hot encoding for columns with <= 8 categories, and binary encoding for columns with more categories \n",
    "columns_for_binary_encoding = []\n",
    "columns_for_onehot_encoding = []\n",
    "for col in nominal_predictors:\n",
    "    print(col, len(data[col].unique()))\n",
    "    if len(data[col].unique()) <= 8:\n",
    "        columns_for_onehot_encoding.append(col)\n",
    "    else:\n",
    "        columns_for_binary_encoding.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a43f2f65-8fb5-4d0f-b7de-71d4cc04f4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mark categorical column as \"category\"\n",
    "pdf_training[nominal_predictors] = pdf_training[nominal_predictors].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ca3c075c-684e-4153-9063-1c2d45809eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoders to encode categorical columns and scalers to scale numerical columns\n",
    "\n",
    "bin_encoder = Pipeline(\n",
    "    steps=[\n",
    "        (\"binary\", BinaryEncoder(handle_missing='value', handle_unknown='value'))\n",
    "    ]\n",
    ")\n",
    "onehot_encoder = Pipeline(\n",
    "    steps=[\n",
    "        (\"onehot\", OneHotEncoder())\n",
    "    ]\n",
    ")\n",
    "std_scaler = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"median\")), (\"standard\", StandardScaler())],\n",
    ")\n",
    "robust_scaler = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"median\")), (\"robust\", RobustScaler())],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f881c286-2d60-47ad-a7a6-4c17fdb594b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compose encoders and scalers in a column transformer\n",
    "transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"binary\", bin_encoder, columns_for_binary_encoding),\n",
    "        (\"onehot\", onehot_encoder, columns_for_onehot_encoding),\n",
    "        (\"robust\", robust_scaler, [COL_AMOUNT]),\n",
    "    ], remainder=\"passthrough\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "80335442-551f-4e85-9c99-b25c0822db62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit column transformer with training data\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "transformer = transformer.fit(pdf_training[predictor_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5a360336-7363-4554-8e04-ab6ddbdaed0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformed column names\n",
    "columns_of_transformed_data = list(\n",
    "    map(lambda name: name.split('__')[1],\n",
    "        list(transformer.get_feature_names_out(predictor_columns))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a9615c4f-c199-4261-8400-da2b4c349676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data type of transformed columns \n",
    "type_mapping = {}\n",
    "for col in columns_of_transformed_data:\n",
    "    if col.split('_')[0] in nominal_predictors:\n",
    "        type_mapping[col] = 'int8'\n",
    "    elif col in numerical_predictors:\n",
    "        type_mapping[col] = 'float'\n",
    "    elif col in target_column:\n",
    "        type_mapping[col] = data.dtypes.to_dict()[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7ce869da-2f24-47bb-8c05-92ba8152b4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform training data\n",
    "preprocessed_training_data = transformer.transform(pdf_training[predictor_columns])\n",
    "\n",
    "# Convert transformed data to panda DataFrame\n",
    "preprocessed_training_data = pd.DataFrame(\n",
    "    preprocessed_training_data, columns=columns_of_transformed_data)\n",
    "# Copy target column\n",
    "preprocessed_training_data[COL_FRAUD] = pdf_training[COL_FRAUD].values\n",
    "preprocessed_training_data = preprocessed_training_data.astype(type_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "081a6b80-dcef-4766-a92e-082ab16eba9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the transformer \n",
    "\n",
    "with open(os.path.join(tabformer_base_path, 'preprocessor.pkl'),'wb') as f:\n",
    "    pickle.dump(transformer, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263bab4e-fc04-40f7-a2bf-28a44f99a245",
   "metadata": {},
   "source": [
    "## Save transformed training data for XGBoost training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "eb2e44b9-3900-4675-b72c-09f5267325bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(tabformer_base_path, 'preprocessor.pkl'),'rb') as f:\n",
    "    loaded_transformer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fcd8fddb-3ace-4932-909a-c3f6c7ec6371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform test data using the transformer fitted on training data\n",
    "pdf_test = data[test_idx].to_pandas()[predictor_columns + target_column]\n",
    "pdf_test[nominal_predictors] = pdf_test[nominal_predictors].astype(\"category\")\n",
    "\n",
    "preprocessed_test_data = loaded_transformer.transform(pdf_test[predictor_columns])\n",
    "preprocessed_test_data = pd.DataFrame(preprocessed_test_data, columns=columns_of_transformed_data)\n",
    "\n",
    "# Copy target column\n",
    "preprocessed_test_data[COL_FRAUD] = pdf_test[COL_FRAUD].values\n",
    "preprocessed_test_data = preprocessed_test_data.astype(type_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d717d0ab-2260-437a-a60a-9a1904c34b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform validation data using the transformer fitted on training data\n",
    "pdf_validation = data[validation_idx].to_pandas()[predictor_columns + target_column]\n",
    "pdf_validation[nominal_predictors] = pdf_validation[nominal_predictors].astype(\"category\")\n",
    "\n",
    "preprocessed_validation_data = loaded_transformer.transform(pdf_validation[predictor_columns])\n",
    "preprocessed_validation_data = pd.DataFrame(preprocessed_validation_data, columns=columns_of_transformed_data)\n",
    "\n",
    "# Copy target column\n",
    "preprocessed_validation_data[COL_FRAUD] = pdf_validation[COL_FRAUD].values\n",
    "preprocessed_validation_data = preprocessed_validation_data.astype(type_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44e6a7e-288c-4864-b02b-1551b19ae946",
   "metadata": {},
   "source": [
    "## Write out the data for XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d773005a-4500-4b63-9950-3699911a19a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training data\n",
    "out_path = os.path.join(tabformer_xgb, 'training.csv')\n",
    "if not os.path.exists(os.path.dirname(out_path)):\n",
    "  os.makedirs(os.path.dirname(out_path))\n",
    "preprocessed_training_data.to_csv(out_path, header=True, index=False, columns=columns_of_transformed_data + target_column)\n",
    "# preprocessed_training_data.to_parquet(out_path, index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1483c50a-eb19-4ef6-9875-cf89de322472",
   "metadata": {},
   "outputs": [],
   "source": [
    "## validation data\n",
    "out_path = os.path.join(tabformer_xgb, 'validation.csv')\n",
    "if not os.path.exists(os.path.dirname(out_path)):\n",
    "  os.makedirs(os.path.dirname(out_path))\n",
    "preprocessed_validation_data.to_csv(out_path, header=True, index=False, columns=columns_of_transformed_data + target_column)\n",
    "# preprocessed_validation_data.to_parquet(out_path, index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "89d47e7f-5bbd-4f46-8111-82eb8a94b802",
   "metadata": {},
   "outputs": [],
   "source": [
    "## test data\n",
    "out_path = os.path.join(tabformer_xgb, 'test.csv')\n",
    "preprocessed_test_data.to_csv(out_path, header=True, index=False, columns=columns_of_transformed_data + target_column)\n",
    "# preprocessed_test_data.to_parquet(out_path, index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a1c4fc5d-13ea-407b-a7e9-1ce223899781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write untransformed test data that has only (renamed) predictor columns and target\n",
    "out_path = os.path.join(tabformer_xgb, 'untransformed_test.csv')\n",
    "pdf_test.to_csv(out_path, header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "236d47d5-a529-4c34-b398-c6f9e1aa2690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete dataFrames that are not needed anymore\n",
    "del(pdf_training)\n",
    "del(pdf_validation)\n",
    "del(pdf_test)\n",
    "del(preprocessed_training_data)\n",
    "del(preprocessed_validation_data)\n",
    "del(preprocessed_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2998bd0-f55b-4783-9f16-39c67902e2d9",
   "metadata": {},
   "source": [
    "## GNN Data\n",
    "\n",
    "### Setting Vertext IDs\n",
    "\n",
    "In order to create a graph, the different vertices need to be assigned unique vertex IDs. Additionally, the IDs needs to be consecutive and positive.\n",
    "\n",
    "There are three nodes groups here: Transactions, Users, and Merchants.\n",
    "\n",
    "This IDs are not used in training, just used for graph processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "dfcb9aaa-12ad-491e-9d5b-270451a496d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the same training data as used for XGBoost\n",
    "data = data[training_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "45881acb-c263-403f-9204-37bf46e48a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a lot of process has occurred, sort the data and reset the index\n",
    "data = data.sort_values(by=[COL_YEAR, COL_MONTH, COL_DAY, COL_TIME], ascending=False)\n",
    "data.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7108c318-ad61-4744-9ef2-8f07242527a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each transaction gets a unique ID\n",
    "COL_TRANSACTION_ID = 'Tx_ID'\n",
    "COL_MERCHANT_ID = 'Merchant_ID'\n",
    "COL_USER_ID = 'User_ID'\n",
    "\n",
    "# The number of transaction is the same as the size of the list, and hence the index value\n",
    "data[COL_TRANSACTION_ID] = data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b6700bb8-36ed-49da-9c2e-cf2754e45aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the max transaction ID to compute first merchant ID\n",
    "max_tx_id = data[COL_TRANSACTION_ID].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "68bd5363-ba91-4aa0-a364-e4c07d973345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(281080, '999682974109284083')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert Merchant string to consecutive integers\n",
    "merchant_name_to_id = dict((v, k) for k, v in data[COL_MERCHANT].unique().to_dict().items())\n",
    "data[COL_MERCHANT_ID] = data[COL_MERCHANT].map(merchant_name_to_id) + (max_tx_id + 1)\n",
    "data[COL_MERCHANT_ID].min(), data[COL_MERCHANT].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fb603a5c-a2c3-4233-b7f7-0c2ae3454e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again, get the max merchant ID to compute first user ID\n",
    "max_merchant_id = data[COL_MERCHANT_ID].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb5b189-85a3-45bc-990b-c4389fd6b127",
   "metadata": {},
   "source": [
    "#### NOTE: the 'User' and 'Card' columns of the original data were used to create updated 'Card' colum\n",
    "You can use user or card as nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "01f0bb8d-6117-4428-857c-1814c459d137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(322197, 326968)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert Card to consecutive IDs\n",
    "id_to_consecutive_id = dict((v, k) for k, v in data[COL_CARD].unique().to_dict().items())\n",
    "data[COL_USER_ID] = data[COL_CARD].map(id_to_consecutive_id) + max_merchant_id + 1\n",
    "data[COL_USER_ID].min(), data[COL_USER_ID].max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "60fa05b4-1a71-4125-880a-c684caf12d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the max user ID\n",
    "max_user_id = data[COL_USER_ID].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2dc3129d-8008-40c2-bf35-412ca6a92cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transaction ID range (0, 281079)\n",
      "Merchant ID range (281080, 322196)\n",
      "User ID range (322197, 326968)\n"
     ]
    }
   ],
   "source": [
    "# Check the the transaction, merchant and user ids are consecutive\n",
    "id_range = data[COL_TRANSACTION_ID].min(), data[COL_TRANSACTION_ID].max()\n",
    "print(f'Transaction ID range {id_range}')\n",
    "id_range = data[COL_MERCHANT_ID].min(), data[COL_MERCHANT_ID].max()\n",
    "print(f'Merchant ID range {id_range}')\n",
    "id_range = data[COL_USER_ID].min(), data[COL_USER_ID].max()\n",
    "print(f'User ID range {id_range}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "15c448ce-9805-4953-8b8c-9011c7dbb64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity checks\n",
    "assert( data[COL_TRANSACTION_ID].max() == data[COL_MERCHANT_ID].min() - 1)\n",
    "assert( data[COL_MERCHANT_ID].max() == data[COL_USER_ID].min() - 1)\n",
    "assert(len(data[COL_USER_ID].unique()) == (data[COL_USER_ID].max() - data[COL_USER_ID].min() + 1))\n",
    "assert(len(data[COL_MERCHANT_ID].unique()) == (data[COL_MERCHANT_ID].max() - data[COL_MERCHANT_ID].min() + 1))\n",
    "assert(len(data[COL_TRANSACTION_ID].unique()) == (data[COL_TRANSACTION_ID].max() - data[COL_TRANSACTION_ID].min() + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb09eb7a-5f2e-44d8-9122-6f8cbe8641b7",
   "metadata": {},
   "source": [
    "## Write out the data for GNN\n",
    "#### Create the Graph Edge Data file\n",
    "\n",
    "The file will be in COO format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3023ac26-53cc-4c80-83cf-e1701ae13dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "COL_GRAPH_SRC = 'src'\n",
    "COL_GRAPH_DST = 'dst'\n",
    "COL_GRAPH_WEIGHT = 'wgt'\n",
    "\n",
    "# User to Transactions\n",
    "U_2_T = cudf.DataFrame()\n",
    "U_2_T[COL_GRAPH_SRC] = data[COL_USER_ID]\n",
    "U_2_T[COL_GRAPH_DST] = data[COL_TRANSACTION_ID]\n",
    "if make_undirected:\n",
    "  T_2_U = cudf.DataFrame()\n",
    "  T_2_U[COL_GRAPH_SRC] = data[COL_TRANSACTION_ID]\n",
    "  T_2_U[COL_GRAPH_DST] = data[COL_USER_ID]\n",
    "  U_2_T = cudf.concat([U_2_T, T_2_U])\n",
    "  del T_2_U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6d7c310c-4621-46d1-b43f-1030b454b413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transactions to Merchants\n",
    "T_2_M = cudf.DataFrame()\n",
    "T_2_M[COL_GRAPH_SRC] = data[COL_MERCHANT_ID]\n",
    "T_2_M[COL_GRAPH_DST] = data[COL_TRANSACTION_ID]\n",
    "\n",
    "if make_undirected:\n",
    "  M_2_T = cudf.DataFrame()\n",
    "  M_2_T[COL_GRAPH_SRC] = data[COL_TRANSACTION_ID]\n",
    "  M_2_T[COL_GRAPH_DST] = data[COL_MERCHANT_ID]\n",
    "  T_2_M = cudf.concat([T_2_M, M_2_T])\n",
    "  del M_2_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "05ec3e2f-6333-42c5-9153-97a5c48e44b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      src  dst  wgt\n",
      "0  322197    0  0.0\n",
      "1  322198    1  0.0\n",
      "2  322199    2  0.0\n",
      "3  322200    3  0.0\n",
      "4  322201    4  0.0\n"
     ]
    }
   ],
   "source": [
    "Edge = cudf.concat([U_2_T, T_2_M])\n",
    "Edge[COL_GRAPH_WEIGHT] = 0.0\n",
    "len(Edge)\n",
    "print(Edge.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "295af6ce-097e-4a5b-84a4-4d7601cf7ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now write out the data\n",
    "out_path = os.path.join (tabformer_gnn, 'edges.csv')\n",
    "\n",
    "if not os.path.exists(os.path.dirname(out_path)):\n",
    "  os.makedirs(os.path.dirname(out_path))\n",
    "  \n",
    "Edge.to_csv(out_path, header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b826d007-01c0-4c06-8cac-23c991028989",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(Edge)\n",
    "del(U_2_T)\n",
    "del(T_2_M)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8d7e1e-74c3-4059-a599-7120ab977e99",
   "metadata": {},
   "source": [
    "## Now the feature data\n",
    "\n",
    "Feature data needs to be is sorted in order, where the row index corresponds to the node ID\n",
    "\n",
    "The data is comprised of three sets of features\n",
    "\n",
    "- Transactions\n",
    "- Users\n",
    "- Merchants\n",
    "\n",
    "To get feature vectors of Transaction nodes, transform the training data using pre-fitted transformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2a58e087-df04-4b75-a5ea-b158c3cd70c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_feature_df = pd.DataFrame(\n",
    "    loaded_transformer.transform(\n",
    "        data[predictor_columns].to_pandas()\n",
    "        ),\n",
    "    columns=columns_of_transformed_data).astype(type_mapping)\n",
    "\n",
    "node_feature_df[COL_FRAUD] = data[COL_FRAUD].to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b03be3d-7007-4711-a973-289527898b3e",
   "metadata": {},
   "source": [
    "### For graph nodes associated with merchant and user, add feature vectors of zeros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "955ee7cf-f22d-4f08-b205-215486d5f686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of graph nodes for users and merchants \n",
    "nr_users_and_merchant_nodes = max_user_id - max_tx_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e0a0d25b-17c1-41ab-b3a7-a2c53d18022b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not spread_features:\n",
    "    # Create feature vector of all zeros for each user and merchant node\n",
    "    empty_feature_df = cudf.DataFrame(\n",
    "        columns=columns_of_transformed_data + target_column,\n",
    "        dtype='int8', \n",
    "        index=range(nr_users_and_merchant_nodes)\n",
    "    )\n",
    "    empty_feature_df = empty_feature_df.fillna(0)\n",
    "    empty_feature_df=empty_feature_df.astype(type_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0a5bb036-3e27-4a1f-b861-a2a741034d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not spread_features:\n",
    "    # Concatenate transaction features followed by features for merchants and user nodes\n",
    "    node_feature_df = pd.concat([node_feature_df, empty_feature_df.to_pandas()]).astype(type_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2da509-b4c4-4158-ab42-45204e543298",
   "metadata": {},
   "source": [
    "## Constructing Features if spread_features = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a6f52b1e-67ca-4bde-80f2-1c0bca636fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User specific columns\n",
    "if spread_features:\n",
    "    user_specific_columns = [COL_CARD, COL_CHIP]\n",
    "    user_specific_columns_of_transformed_data = []\n",
    "\n",
    "    for col in node_feature_df.columns:\n",
    "        if col.split('_')[0] in user_specific_columns:\n",
    "            user_specific_columns_of_transformed_data.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "455e0189-d2a0-4d58-bcc7-fba2ec9599dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merchant specific columns\n",
    "if spread_features:\n",
    "    merchant_specific_columns = [COL_MERCHANT, COL_CITY, COL_ZIP, COL_MCC]\n",
    "    merchant_specific_columns_of_transformed_data = []\n",
    "    \n",
    "    for col in node_feature_df.columns:\n",
    "        if col.split('_')[0] in merchant_specific_columns:\n",
    "            merchant_specific_columns_of_transformed_data.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "02d70b64-ecd5-45f2-8f92-4a24d6bb1ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transaction specific columns\n",
    "if spread_features:\n",
    "    transaction_specific_columns = list(\n",
    "        set(numerical_predictors).union(nominal_predictors)\n",
    "        - set(user_specific_columns).union(merchant_specific_columns))\n",
    "    transaction_specific_columns_of_transformed_data = []\n",
    "    \n",
    "    for col in node_feature_df.columns:\n",
    "        if col.split('_')[0] in transaction_specific_columns:\n",
    "            transaction_specific_columns_of_transformed_data.append(col)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "567fbab2-6dbd-43fb-b7fe-25e1d247a2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "if spread_features:\n",
    "    # Find indices of unique merchants\n",
    "    idx_df = cudf.DataFrame()\n",
    "    idx_df[COL_MERCHANT_ID] =  data[COL_MERCHANT_ID]\n",
    "    idx_df = idx_df.sort_values(by=COL_MERCHANT_ID)\n",
    "    idx_df = idx_df.drop_duplicates(subset=COL_MERCHANT_ID)\n",
    "    assert((data.iloc[idx_df.index][COL_MERCHANT_ID] == idx_df[COL_MERCHANT_ID]).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "db7bcb07-2726-49d0-abc5-ac093aa58179",
   "metadata": {},
   "outputs": [],
   "source": [
    "if spread_features:\n",
    "    # Copy merchant specific columns, and set the rest to zero\n",
    "    merchant_specific_feature_df = node_feature_df.iloc[idx_df.index.to_numpy()]\n",
    "    merchant_specific_feature_df.\\\n",
    "    loc[:, \n",
    "        transaction_specific_columns_of_transformed_data +\n",
    "          user_specific_columns_of_transformed_data] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f701e0ee-ee09-4e21-84fc-a54ee542cbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if spread_features:\n",
    "    # Find indices of unique users\n",
    "    idx_df = cudf.DataFrame()\n",
    "    idx_df[COL_USER_ID] = data[COL_USER_ID]\n",
    "    idx_df = idx_df.sort_values(by=COL_USER_ID)\n",
    "    idx_df = idx_df.drop_duplicates(subset=COL_USER_ID)\n",
    "    assert((data.iloc[idx_df.index][COL_USER_ID] == idx_df[COL_USER_ID]).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "41324222-5ac2-4d78-a5ed-58bcdd7290a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if spread_features:\n",
    "    # Copy user specific columns, and set the rest to zero\n",
    "    user_specific_feature_df = node_feature_df.iloc[idx_df.index.to_numpy()]\n",
    "    user_specific_feature_df.\\\n",
    "    loc[:,\n",
    "        transaction_specific_columns_of_transformed_data +\n",
    "          merchant_specific_columns_of_transformed_data] = 0.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "511f68ea-9e6f-411f-96ba-16aea3247742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate features of node, user and merchant\n",
    "if spread_features:\n",
    "    \n",
    "    node_feature_df[merchant_specific_columns_of_transformed_data] = 0.0\n",
    "    node_feature_df[user_specific_columns_of_transformed_data] = 0.0\n",
    "    node_feature_df = pd.concat(\n",
    "        [node_feature_df, merchant_specific_feature_df, user_specific_feature_df]\n",
    "        ).astype(type_mapping)\n",
    "    \n",
    "    # features to save\n",
    "    node_feature_df = node_feature_df[\n",
    "        transaction_specific_columns_of_transformed_data +\n",
    "        merchant_specific_columns_of_transformed_data +\n",
    "        user_specific_columns_of_transformed_data + [COL_FRAUD]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2a605c62-f421-4139-87b1-567aaf8ab985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target labels to save\n",
    "label_df = node_feature_df[[COL_FRAUD]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d2603276-a2db-4b0f-87c7-5e07b085d883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove target label from feature vectors\n",
    "_ = node_feature_df.drop(columns=[COL_FRAUD], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7e6665-a2d9-4d05-a16f-083adfd7913b",
   "metadata": {},
   "source": [
    "## Write out node features and target labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4bef7ddd-fc1c-44b6-ae87-52f352df7161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write node target label to csv file\n",
    "out_path = os.path.join(tabformer_gnn, 'labels.csv')\n",
    "\n",
    "if not os.path.exists(os.path.dirname(out_path)):\n",
    "  os.makedirs(os.path.dirname(out_path))\n",
    "\n",
    "label_df.to_csv(out_path, header=False, index=False)\n",
    "# label_df.to_parquet(out_path, index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7d80873d-cfd8-4b79-a1c9-381404170415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write node features to csv file\n",
    "out_path = os.path.join(tabformer_gnn, 'features.csv')\n",
    "\n",
    "if not os.path.exists(os.path.dirname(out_path)):\n",
    "  os.makedirs(os.path.dirname(out_path))\n",
    "node_feature_df[columns_of_transformed_data].to_csv(out_path, header=True, index=False)\n",
    "# node_feature_df.to_parquet(out_path, index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "69e58521-19b6-4b42-98c4-c70d4f3fc776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete dataFrames\n",
    "del data\n",
    "del node_feature_df\n",
    "del label_df\n",
    "\n",
    "if spread_features:\n",
    "    del merchant_specific_feature_df\n",
    "    del user_specific_feature_df\n",
    "else:\n",
    "    del empty_feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d8677dfe-78a0-4f40-8cef-84d13a057060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "281080"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of transaction nodes, needed for GNN training\n",
    "nr_transaction_nodes = max_tx_id + 1\n",
    "nr_transaction_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2ec6f74b-a115-4314-b121-d0b35f341161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Max number of cards per user, needed for inference\n",
    "max_nr_cards_per_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5a1afc28-93d1-43e0-8af9-4d8592dcb1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save variables for training and inference\n",
    "variables_to_save = {\n",
    "    k: v for k, v in globals().items() if isinstance(v, (str, int)) and k.startswith('COL_')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "80c2a6e7-4b77-4c60-ae7f-40f4d4f1fce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_to_save['NUM_TRANSACTION_NODES'] = int(nr_transaction_nodes)\n",
    "variables_to_save['MAX_NR_CARDS_PER_USER'] = int(max_nr_cards_per_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d63faaa9-e294-41c6-aa01-d2edd9944895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dictionary to a JSON file\n",
    "\n",
    "with open(os.path.join(tabformer_base_path, 'variables.json'), 'w') as json_file:\n",
    "    json.dump(variables_to_save, json_file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (fraud_conda_env)",
   "language": "python",
   "name": "fraud_conda_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
