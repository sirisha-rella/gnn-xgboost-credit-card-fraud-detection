{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3bdcb07",
   "metadata": {},
   "source": [
    "# Deploying Models in Triton\n",
    "\n",
    "The goal of the notebook is to deploy models to Triton and show how to perform high-performance inference for production purposes.\n",
    "\n",
    "We will be doing following steps as part of the notebook:\n",
    "\n",
    "- Convert GNN pytorch model to ONNX format\n",
    "- Deploying models to Triton Inference Server and starting the server\n",
    "- Submitting the inference requests\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7c29a1",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aeda5947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import cudf\n",
    "import cupy as cp\n",
    "\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "import os\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ca2a8fa-8c54-4fa7-9c9a-14ff9e4801ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definition of the trained Graph\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, n_hops, dropout_prob=0.25):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "\n",
    "        # list of conv layers\n",
    "        self.convs = nn.ModuleList()\n",
    "        # add first conv layer to the list\n",
    "        self.convs.append(SAGEConv(in_channels, hidden_channels))\n",
    "        # add the remaining conv layers to the list\n",
    "        for _ in range(n_hops - 1):\n",
    "            self.convs.append(SAGEConv(hidden_channels, hidden_channels))\n",
    "        \n",
    "        # output layer\n",
    "        self.fc = nn.Linear(hidden_channels, out_channels)        \n",
    "\n",
    "    def forward(self, x, edge_index, return_hidden=False):\n",
    "        for conv in self.convs:\n",
    "            x = conv(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=0.5, training=self.training)\n",
    "            \n",
    "        if return_hidden:\n",
    "            return x\n",
    "        else:\n",
    "            return self.fc(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844c7963-02fc-492d-897d-6bee4b0ba9c4",
   "metadata": {},
   "source": [
    "# Convert GNN PyTorch model to ONNX\n",
    "\n",
    "We will be converting the PyTorch model that was created in the training notebook to an ONNX model for deploying to the Triton Inference Server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22eac8c5-98ed-4c61-99f4-91d30e085222",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_base_path = '../data/TabFormer'\n",
    "model_root_dir = os.path.join(dataset_base_path, 'models')\n",
    "gnn_model_path = os.path.join(model_root_dir, 'node_embedder.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2c9b3f2-db2a-4019-9a21-79b7e85eb6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1713523/1763434492.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  gnn_model=torch.load(gnn_model_path, map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GraphSAGE(\n",
       "  (convs): ModuleList(\n",
       "    (0): SAGEConv(74, 32, aggr=mean)\n",
       "    (1): SAGEConv(32, 32, aggr=mean)\n",
       "  )\n",
       "  (fc): Linear(in_features=32, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the pre-trained GraphSAGE model for generating node embeddings\n",
    "gnn_model = GraphSAGE(in_channels=74, hidden_channels=32, out_channels=2, n_hops=2)  # Adjust based on your setup\n",
    "gnn_model=torch.load(gnn_model_path, map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "\n",
    "# gnn_model = torch.load(gnn_model_path, map_location=torch.device('cuda'))\n",
    "gnn_model.eval()  # Set the model to evaluation mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "589039d7-99d2-405d-891c-9b0fb31ccc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on transformed data\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "dummy_x = torch.rand(4, 74, dtype=torch.float32) \n",
    "dummy_x = dummy_x.to(device)\n",
    "\n",
    "dummy_edge_index = torch.tensor([[0, 1, 2, 3],  # Example edges\n",
    "                               [1, 2, 3, 2]], dtype=torch.int64).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b986380-5d18-4ec4-9343-543660f5fd8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported graph: graph(%l_x_ : Float(*, 74, strides=[74, 1], requires_grad=0, device=cuda:0),\n",
      "      %l_edge_index_ : Long(*, *, strides=[4, 1], requires_grad=0, device=cuda:0),\n",
      "      %convs.0.lin_l.weight : Float(32, 74, strides=[74, 1], requires_grad=1, device=cuda:0),\n",
      "      %convs.0.lin_l.bias : Float(32, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %convs.1.lin_l.weight : Float(32, 32, strides=[32, 1], requires_grad=1, device=cuda:0),\n",
      "      %convs.1.lin_l.bias : Float(32, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %onnx::MatMul_113 : Float(74, 32, strides=[1, 74], requires_grad=0, device=cuda:0),\n",
      "      %onnx::MatMul_116 : Float(32, 32, strides=[1, 32], requires_grad=0, device=cuda:0)):\n",
      "  %/convs.0/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/convs.0/Constant\"](), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.0\n",
      "  %/convs.0/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/convs.0/Constant_1\"](), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.0\n",
      "  %/convs.0/Gather_output_0 : Long(*, strides=[1], requires_grad=0, device=cuda:0) = onnx::Gather[axis=0, onnx_name=\"/convs.0/Gather\"](%l_edge_index_, %/convs.0/Constant_1_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.0 # /tmp/torch_geometric.nn.conv.sage_conv_SAGEConv_propagate_y30gl4i5.py:57:0\n",
      "  %/convs.0/Gather_1_output_0 : Long(*, strides=[1], requires_grad=0, device=cuda:0) = onnx::Gather[axis=0, onnx_name=\"/convs.0/Gather_1\"](%l_edge_index_, %/convs.0/Constant_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.0 # /tmp/torch_geometric.nn.conv.sage_conv_SAGEConv_propagate_y30gl4i5.py:58:0\n",
      "  %/convs.0/Gather_2_output_0 : Float(*, 74, strides=[74, 1], requires_grad=0, device=cuda:0) = onnx::Gather[axis=-2, onnx_name=\"/convs.0/Gather_2\"](%l_x_, %/convs.0/Gather_1_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.0 # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/nn/conv/message_passing.py:317:0\n",
      "  %/convs.0/Shape_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/convs.0/Shape\"](%l_x_), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.0 # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/nn/conv/message_passing.py:303:0\n",
      "  %/convs.0/Constant_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/convs.0/Constant_2\"](), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.0 # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/nn/conv/message_passing.py:303:0\n",
      "  %/convs.0/Constant_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-2}, onnx_name=\"/convs.0/Constant_3\"](), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.0 # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/nn/conv/message_passing.py:303:0\n",
      "  %/convs.0/Constant_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/convs.0/Constant_4\"](), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.0 # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/nn/conv/message_passing.py:303:0\n",
      "  %/convs.0/Slice_output_0 : Long(1, strides=[1], device=cpu) = onnx::Slice[onnx_name=\"/convs.0/Slice\"](%/convs.0/Shape_output_0, %/convs.0/Constant_3_output_0, %/convs.0/Constant_4_output_0, %/convs.0/Constant_2_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.0 # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/nn/conv/message_passing.py:303:0\n",
      "  %/convs.0/Squeeze_output_0 : Long(device=cpu) = onnx::Squeeze[axes=[0], onnx_name=\"/convs.0/Squeeze\"](%/convs.0/Slice_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.0 # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/nn/conv/message_passing.py:303:0\n",
      "  %/convs.0/aggr_module/Shape_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/convs.0/aggr_module/Shape\"](%/convs.0/Gather_2_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.0/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:65:0\n",
      "  %/convs.0/aggr_module/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/convs.0/aggr_module/Constant\"](), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.0/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:65:0\n",
      "  %/convs.0/aggr_module/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/convs.0/aggr_module/Gather\"](%/convs.0/aggr_module/Shape_output_0, %/convs.0/aggr_module/Constant_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.0/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:65:0\n",
      "  %/convs.0/aggr_module/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0], onnx_name=\"/convs.0/aggr_module/Unsqueeze\"](%/convs.0/Squeeze_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.0/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module\n",
      "  %/convs.0/aggr_module/Concat_output_0 : Long(1, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/convs.0/aggr_module/Concat\"](%/convs.0/aggr_module/Unsqueeze_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.0/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:78:0\n",
      "  %/convs.0/aggr_module/Shape_1_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/convs.0/aggr_module/Shape_1\"](%/convs.0/Gather_2_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.0/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:79:0\n",
      "  %/convs.0/aggr_module/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/convs.0/aggr_module/Constant_1\"](), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.0/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:79:0\n",
      "  %/convs.0/aggr_module/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/convs.0/aggr_module/Gather_1\"](%/convs.0/aggr_module/Shape_1_output_0, %/convs.0/aggr_module/Constant_1_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.0/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:79:0\n",
      "  %/convs.0/aggr_module/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0], onnx_name=\"/convs.0/aggr_module/Unsqueeze_1\"](%/convs.0/aggr_module/Gather_1_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.0/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module\n",
      "  %/convs.0/aggr_module/Concat_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/convs.0/aggr_module/Concat_1\"](%/convs.0/aggr_module/Unsqueeze_1_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.0/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:79:0\n",
      "  %/convs.0/aggr_module/ConstantOfShape_output_0 : Float(*, strides=[1], requires_grad=0, device=cuda:0) = onnx::ConstantOfShape[value={1}, onnx_name=\"/convs.0/aggr_module/ConstantOfShape\"](%/convs.0/aggr_module/Concat_1_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.0/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:79:0\n",
      "  %/convs.0/aggr_module/ConstantOfShape_1_output_0 : Float(*, strides=[1], requires_grad=0, device=cuda:0) = onnx::ConstantOfShape[value={0}, onnx_name=\"/convs.0/aggr_module/ConstantOfShape_1\"](%/convs.0/aggr_module/Concat_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.0/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:78:0\n",
      "  %/convs.0/aggr_module/Shape_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/convs.0/aggr_module/Shape_2\"](%/convs.0/aggr_module/ConstantOfShape_1_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.0/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:79:0\n",
      "  %/convs.0/aggr_module/ConstantOfShape_2_output_0 : Float(*, device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name=\"/convs.0/aggr_module/ConstantOfShape_2\"](%/convs.0/aggr_module/Shape_2_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.0/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:79:0\n",
      "  %/convs.0/aggr_module/ScatterElements_output_0 : Float(*, device=cpu) = onnx::ScatterElements[axis=0, onnx_name=\"/convs.0/aggr_module/ScatterElements\"](%/convs.0/aggr_module/ConstantOfShape_2_output_0, %/convs.0/Gather_output_0, %/convs.0/aggr_module/ConstantOfShape_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.0/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:79:0\n",
      "  %/convs.0/aggr_module/Add_output_0 : Float(*, strides=[1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name=\"/convs.0/aggr_module/Add\"](%/convs.0/aggr_module/ConstantOfShape_1_output_0, %/convs.0/aggr_module/ScatterElements_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.0/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:79:0\n",
      "  %/convs.0/aggr_module/Constant_2_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/convs.0/aggr_module/Constant_2\"](), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.0/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:80:0\n",
      "  %onnx::Clip_40 : Tensor? = prim::Constant(), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.0/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:80:0\n",
      "  %/convs.0/aggr_module/Clip_output_0 : Float(*, strides=[1], requires_grad=0, device=cuda:0) = onnx::Clip[onnx_name=\"/convs.0/aggr_module/Clip\"](%/convs.0/aggr_module/Add_output_0, %/convs.0/aggr_module/Constant_2_output_0, %onnx::Clip_40), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.0/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:80:0\n",
      "  %/convs.0/aggr_module/Constant_3_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  1 [ CPULongType{2} ], onnx_name=\"/convs.0/aggr_module/Constant_3\"](), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.0/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:179:0\n",
      "  %/convs.0/aggr_module/Reshape_output_0 : Long(*, *, strides=[1, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[onnx_name=\"/convs.0/aggr_module/Reshape\"](%/convs.0/Gather_output_0, %/convs.0/aggr_module/Constant_3_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.0/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:179:0\n",
      "  %/convs.0/aggr_module/Shape_3_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/convs.0/aggr_module/Shape_3\"](%/convs.0/Gather_2_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.0/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:179:0\n",
      "  %/convs.0/aggr_module/Expand_output_0 : Long(*, *, strides=[1, 0], requires_grad=0, device=cuda:0) = onnx::Expand[onnx_name=\"/convs.0/aggr_module/Expand\"](%/convs.0/aggr_module/Reshape_output_0, %/convs.0/aggr_module/Shape_3_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.0/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:179:0\n",
      "  %/convs.0/aggr_module/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0], onnx_name=\"/convs.0/aggr_module/Unsqueeze_2\"](%/convs.0/Squeeze_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.0/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module\n",
      "  %/convs.0/aggr_module/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0], onnx_name=\"/convs.0/aggr_module/Unsqueeze_3\"](%/convs.0/aggr_module/Gather_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.0/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module\n",
      "  %/convs.0/aggr_module/Concat_2_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/convs.0/aggr_module/Concat_2\"](%/convs.0/aggr_module/Unsqueeze_2_output_0, %/convs.0/aggr_module/Unsqueeze_3_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.0/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:83:0\n",
      "  %/convs.0/aggr_module/ConstantOfShape_3_output_0 : Float(*, *, strides=[74, 1], requires_grad=0, device=cuda:0) = onnx::ConstantOfShape[value={0}, onnx_name=\"/convs.0/aggr_module/ConstantOfShape_3\"](%/convs.0/aggr_module/Concat_2_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.0/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:83:0\n",
      "  %/convs.0/aggr_module/Shape_4_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/convs.0/aggr_module/Shape_4\"](%/convs.0/aggr_module/ConstantOfShape_3_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.0/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:83:0\n",
      "  %/convs.0/aggr_module/ConstantOfShape_4_output_0 : Float(*, *, device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name=\"/convs.0/aggr_module/ConstantOfShape_4\"](%/convs.0/aggr_module/Shape_4_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.0/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:83:0\n",
      "  %/convs.0/aggr_module/ScatterElements_1_output_0 : Float(*, *, device=cpu) = onnx::ScatterElements[axis=0, onnx_name=\"/convs.0/aggr_module/ScatterElements_1\"](%/convs.0/aggr_module/ConstantOfShape_4_output_0, %/convs.0/aggr_module/Expand_output_0, %/convs.0/Gather_2_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.0/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:83:0\n",
      "  %/convs.0/aggr_module/Add_1_output_0 : Float(*, *, strides=[74, 1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name=\"/convs.0/aggr_module/Add_1\"](%/convs.0/aggr_module/ConstantOfShape_3_output_0, %/convs.0/aggr_module/ScatterElements_1_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.0/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:83:0\n",
      "  %/convs.0/aggr_module/Constant_4_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  1 [ CPULongType{2} ], onnx_name=\"/convs.0/aggr_module/Constant_4\"](), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.0/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:179:0\n",
      "  %/convs.0/aggr_module/Reshape_1_output_0 : Float(*, *, strides=[1, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[onnx_name=\"/convs.0/aggr_module/Reshape_1\"](%/convs.0/aggr_module/Clip_output_0, %/convs.0/aggr_module/Constant_4_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.0/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:179:0\n",
      "  %/convs.0/aggr_module/Shape_5_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/convs.0/aggr_module/Shape_5\"](%/convs.0/aggr_module/Add_1_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.0/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:179:0\n",
      "  %/convs.0/aggr_module/Expand_1_output_0 : Float(*, *, strides=[1, 0], requires_grad=0, device=cuda:0) = onnx::Expand[onnx_name=\"/convs.0/aggr_module/Expand_1\"](%/convs.0/aggr_module/Reshape_1_output_0, %/convs.0/aggr_module/Shape_5_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.0/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:179:0\n",
      "  %/convs.0/aggr_module/Div_output_0 : Float(*, *, strides=[74, 1], requires_grad=0, device=cuda:0) = onnx::Div[onnx_name=\"/convs.0/aggr_module/Div\"](%/convs.0/aggr_module/Add_1_output_0, %/convs.0/aggr_module/Expand_1_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.0/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:85:0\n",
      "  %/convs.0/lin_l/Gemm_output_0 : Float(*, 32, strides=[32, 1], requires_grad=1, device=cuda:0) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name=\"/convs.0/lin_l/Gemm\"](%/convs.0/aggr_module/Div_output_0, %convs.0.lin_l.weight, %convs.0.lin_l.bias), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.0/torch_geometric.nn.dense.linear.Linear::lin_l # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/nn/dense/linear.py:147:0\n",
      "  %/convs.0/lin_r/MatMul_output_0 : Float(*, 32, strides=[32, 1], requires_grad=1, device=cuda:0) = onnx::MatMul[onnx_name=\"/convs.0/lin_r/MatMul\"](%l_x_, %onnx::MatMul_113), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.0/torch_geometric.nn.dense.linear.Linear::lin_r # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/nn/dense/linear.py:147:0\n",
      "  %/convs.0/Add_output_0 : Float(*, 32, strides=[32, 1], requires_grad=1, device=cuda:0) = onnx::Add[onnx_name=\"/convs.0/Add\"](%/convs.0/lin_l/Gemm_output_0, %/convs.0/lin_r/MatMul_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.0 # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/nn/conv/sage_conv.py:139:0\n",
      "  %/Relu_output_0 : Float(*, 32, strides=[32, 1], requires_grad=1, device=cuda:0) = onnx::Relu[onnx_name=\"/Relu\"](%/convs.0/Add_output_0), scope: __main__.GraphSAGE:: # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch/nn/functional.py:1704:0\n",
      "  %/convs.1/Gather_output_0 : Float(*, 32, strides=[32, 1], requires_grad=1, device=cuda:0) = onnx::Gather[axis=-2, onnx_name=\"/convs.1/Gather\"](%/Relu_output_0, %/convs.0/Gather_1_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.1 # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/nn/conv/message_passing.py:317:0\n",
      "  %/convs.1/Shape_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/convs.1/Shape\"](%/Relu_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.1 # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/nn/conv/message_passing.py:303:0\n",
      "  %/convs.1/Constant_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/convs.1/Constant\"](), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.1 # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/nn/conv/message_passing.py:303:0\n",
      "  %/convs.1/Constant_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-2}, onnx_name=\"/convs.1/Constant_1\"](), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.1 # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/nn/conv/message_passing.py:303:0\n",
      "  %/convs.1/Constant_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/convs.1/Constant_2\"](), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.1 # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/nn/conv/message_passing.py:303:0\n",
      "  %/convs.1/Slice_output_0 : Long(1, strides=[1], device=cpu) = onnx::Slice[onnx_name=\"/convs.1/Slice\"](%/convs.1/Shape_output_0, %/convs.1/Constant_1_output_0, %/convs.1/Constant_2_output_0, %/convs.1/Constant_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.1 # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/nn/conv/message_passing.py:303:0\n",
      "  %/convs.1/Squeeze_output_0 : Long(device=cpu) = onnx::Squeeze[axes=[0], onnx_name=\"/convs.1/Squeeze\"](%/convs.1/Slice_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.1 # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/nn/conv/message_passing.py:303:0\n",
      "  %/convs.1/aggr_module/Shape_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/convs.1/aggr_module/Shape\"](%/convs.1/Gather_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.1/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:65:0\n",
      "  %/convs.1/aggr_module/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/convs.1/aggr_module/Constant\"](), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.1/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:65:0\n",
      "  %/convs.1/aggr_module/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/convs.1/aggr_module/Gather\"](%/convs.1/aggr_module/Shape_output_0, %/convs.1/aggr_module/Constant_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.1/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:65:0\n",
      "  %/convs.1/aggr_module/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0], onnx_name=\"/convs.1/aggr_module/Unsqueeze\"](%/convs.1/Squeeze_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.1/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module\n",
      "  %/convs.1/aggr_module/Concat_output_0 : Long(1, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/convs.1/aggr_module/Concat\"](%/convs.1/aggr_module/Unsqueeze_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.1/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:78:0\n",
      "  %/convs.1/aggr_module/Shape_1_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/convs.1/aggr_module/Shape_1\"](%/convs.1/Gather_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.1/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:79:0\n",
      "  %/convs.1/aggr_module/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/convs.1/aggr_module/Constant_1\"](), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.1/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:79:0\n",
      "  %/convs.1/aggr_module/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/convs.1/aggr_module/Gather_1\"](%/convs.1/aggr_module/Shape_1_output_0, %/convs.1/aggr_module/Constant_1_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.1/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:79:0\n",
      "  %/convs.1/aggr_module/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0], onnx_name=\"/convs.1/aggr_module/Unsqueeze_1\"](%/convs.1/aggr_module/Gather_1_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.1/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module\n",
      "  %/convs.1/aggr_module/Concat_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/convs.1/aggr_module/Concat_1\"](%/convs.1/aggr_module/Unsqueeze_1_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.1/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:79:0\n",
      "  %/convs.1/aggr_module/ConstantOfShape_output_0 : Float(*, strides=[1], requires_grad=0, device=cuda:0) = onnx::ConstantOfShape[value={1}, onnx_name=\"/convs.1/aggr_module/ConstantOfShape\"](%/convs.1/aggr_module/Concat_1_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.1/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:79:0\n",
      "  %/convs.1/aggr_module/ConstantOfShape_1_output_0 : Float(*, strides=[1], requires_grad=0, device=cuda:0) = onnx::ConstantOfShape[value={0}, onnx_name=\"/convs.1/aggr_module/ConstantOfShape_1\"](%/convs.1/aggr_module/Concat_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.1/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:78:0\n",
      "  %/convs.1/aggr_module/Shape_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/convs.1/aggr_module/Shape_2\"](%/convs.1/aggr_module/ConstantOfShape_1_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.1/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:79:0\n",
      "  %/convs.1/aggr_module/ConstantOfShape_2_output_0 : Float(*, device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name=\"/convs.1/aggr_module/ConstantOfShape_2\"](%/convs.1/aggr_module/Shape_2_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.1/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:79:0\n",
      "  %/convs.1/aggr_module/ScatterElements_output_0 : Float(*, device=cpu) = onnx::ScatterElements[axis=0, onnx_name=\"/convs.1/aggr_module/ScatterElements\"](%/convs.1/aggr_module/ConstantOfShape_2_output_0, %/convs.0/Gather_output_0, %/convs.1/aggr_module/ConstantOfShape_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.1/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:79:0\n",
      "  %/convs.1/aggr_module/Add_output_0 : Float(*, strides=[1], requires_grad=0, device=cuda:0) = onnx::Add[onnx_name=\"/convs.1/aggr_module/Add\"](%/convs.1/aggr_module/ConstantOfShape_1_output_0, %/convs.1/aggr_module/ScatterElements_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.1/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:79:0\n",
      "  %/convs.1/aggr_module/Constant_2_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/convs.1/aggr_module/Constant_2\"](), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.1/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:80:0\n",
      "  %onnx::Clip_89 : Tensor? = prim::Constant(), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.1/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:80:0\n",
      "  %/convs.1/aggr_module/Clip_output_0 : Float(*, strides=[1], requires_grad=0, device=cuda:0) = onnx::Clip[onnx_name=\"/convs.1/aggr_module/Clip\"](%/convs.1/aggr_module/Add_output_0, %/convs.1/aggr_module/Constant_2_output_0, %onnx::Clip_89), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.1/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:80:0\n",
      "  %/convs.1/aggr_module/Shape_3_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/convs.1/aggr_module/Shape_3\"](%/convs.1/Gather_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.1/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:179:0\n",
      "  %/convs.1/aggr_module/Expand_output_0 : Long(*, *, strides=[1, 0], requires_grad=0, device=cuda:0) = onnx::Expand[onnx_name=\"/convs.1/aggr_module/Expand\"](%/convs.0/aggr_module/Reshape_output_0, %/convs.1/aggr_module/Shape_3_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.1/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:179:0\n",
      "  %/convs.1/aggr_module/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0], onnx_name=\"/convs.1/aggr_module/Unsqueeze_2\"](%/convs.1/Squeeze_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.1/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module\n",
      "  %/convs.1/aggr_module/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0], onnx_name=\"/convs.1/aggr_module/Unsqueeze_3\"](%/convs.1/aggr_module/Gather_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.1/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module\n",
      "  %/convs.1/aggr_module/Concat_2_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/convs.1/aggr_module/Concat_2\"](%/convs.1/aggr_module/Unsqueeze_2_output_0, %/convs.1/aggr_module/Unsqueeze_3_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.1/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:83:0\n",
      "  %/convs.1/aggr_module/ConstantOfShape_3_output_0 : Float(*, *, strides=[32, 1], requires_grad=0, device=cuda:0) = onnx::ConstantOfShape[value={0}, onnx_name=\"/convs.1/aggr_module/ConstantOfShape_3\"](%/convs.1/aggr_module/Concat_2_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.1/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:83:0\n",
      "  %/convs.1/aggr_module/Shape_4_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/convs.1/aggr_module/Shape_4\"](%/convs.1/aggr_module/ConstantOfShape_3_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.1/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:83:0\n",
      "  %/convs.1/aggr_module/ConstantOfShape_4_output_0 : Float(*, *, device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name=\"/convs.1/aggr_module/ConstantOfShape_4\"](%/convs.1/aggr_module/Shape_4_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.1/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:83:0\n",
      "  %/convs.1/aggr_module/ScatterElements_1_output_0 : Float(*, *, device=cpu) = onnx::ScatterElements[axis=0, onnx_name=\"/convs.1/aggr_module/ScatterElements_1\"](%/convs.1/aggr_module/ConstantOfShape_4_output_0, %/convs.1/aggr_module/Expand_output_0, %/convs.1/Gather_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.1/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:83:0\n",
      "  %/convs.1/aggr_module/Add_1_output_0 : Float(*, *, strides=[32, 1], requires_grad=1, device=cuda:0) = onnx::Add[onnx_name=\"/convs.1/aggr_module/Add_1\"](%/convs.1/aggr_module/ConstantOfShape_3_output_0, %/convs.1/aggr_module/ScatterElements_1_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.1/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:83:0\n",
      "  %/convs.1/aggr_module/Constant_3_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  1 [ CPULongType{2} ], onnx_name=\"/convs.1/aggr_module/Constant_3\"](), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.1/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:179:0\n",
      "  %/convs.1/aggr_module/Reshape_output_0 : Float(*, *, strides=[1, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[onnx_name=\"/convs.1/aggr_module/Reshape\"](%/convs.1/aggr_module/Clip_output_0, %/convs.1/aggr_module/Constant_3_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.1/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:179:0\n",
      "  %/convs.1/aggr_module/Shape_5_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/convs.1/aggr_module/Shape_5\"](%/convs.1/aggr_module/Add_1_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.1/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:179:0\n",
      "  %/convs.1/aggr_module/Expand_1_output_0 : Float(*, *, strides=[1, 0], requires_grad=0, device=cuda:0) = onnx::Expand[onnx_name=\"/convs.1/aggr_module/Expand_1\"](%/convs.1/aggr_module/Reshape_output_0, %/convs.1/aggr_module/Shape_5_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.1/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:179:0\n",
      "  %/convs.1/aggr_module/Div_output_0 : Float(*, *, strides=[32, 1], requires_grad=1, device=cuda:0) = onnx::Div[onnx_name=\"/convs.1/aggr_module/Div\"](%/convs.1/aggr_module/Add_1_output_0, %/convs.1/aggr_module/Expand_1_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.1/torch_geometric.nn.aggr.basic.MeanAggregation::aggr_module # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:85:0\n",
      "  %/convs.1/lin_l/Gemm_output_0 : Float(*, 32, strides=[32, 1], requires_grad=1, device=cuda:0) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name=\"/convs.1/lin_l/Gemm\"](%/convs.1/aggr_module/Div_output_0, %convs.1.lin_l.weight, %convs.1.lin_l.bias), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.1/torch_geometric.nn.dense.linear.Linear::lin_l # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/nn/dense/linear.py:147:0\n",
      "  %/convs.1/lin_r/MatMul_output_0 : Float(*, 32, strides=[32, 1], requires_grad=1, device=cuda:0) = onnx::MatMul[onnx_name=\"/convs.1/lin_r/MatMul\"](%/Relu_output_0, %onnx::MatMul_116), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.1/torch_geometric.nn.dense.linear.Linear::lin_r # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/nn/dense/linear.py:147:0\n",
      "  %/convs.1/Add_output_0 : Float(*, 32, strides=[32, 1], requires_grad=1, device=cuda:0) = onnx::Add[onnx_name=\"/convs.1/Add\"](%/convs.1/lin_l/Gemm_output_0, %/convs.1/lin_r/MatMul_output_0), scope: __main__.GraphSAGE::/torch_geometric.nn.conv.sage_conv.SAGEConv::convs.1 # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch_geometric/nn/conv/sage_conv.py:139:0\n",
      "  %output : Float(*, 32, strides=[32, 1], requires_grad=1, device=cuda:0) = onnx::Relu[onnx_name=\"/Relu_1\"](%/convs.1/Add_output_0), scope: __main__.GraphSAGE:: # /home/horde/miniconda3/envs/fraud_conda_env/lib/python3.11/site-packages/torch/nn/functional.py:1704:0\n",
      "  return (%output)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1713523/2458193762.py:23: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if return_hidden:\n"
     ]
    }
   ],
   "source": [
    "onnx_file_path = 'model_repository/model/1/gnn_model.onnx'\n",
    "\n",
    "torch.onnx.export(\n",
    "    gnn_model,  # The model to export\n",
    "    (dummy_x, dummy_edge_index, True),  # Input data (node features, edge indices, hidden=True)\n",
    "    onnx_file_path,  # Path where the ONNX model will be saved\n",
    "    export_params=True,  # Export model parameters (weights)\n",
    "    opset_version=11,  # ONNX opset version (adjust as needed, 11 is generally fine)\n",
    "    input_names=['l_x_', 'l_edge_index_'], \n",
    "    output_names=['output'],  \n",
    "    dynamic_axes={  \n",
    "        'l_x_': {0: 'batch_size'},  # Allow the first dimension of 'l_x_' to be dynamic (batch size)\n",
    "        'l_edge_index_': {0: 'num_edges',  1: 'num_edges'},  # Allow the first and second dimension of 'l_edge_index_' to be dynamic (number of edges)\n",
    "    },\n",
    "    verbose=True  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136f9564-29bd-4b93-bf24-eef80dc535fb",
   "metadata": {},
   "source": [
    "## Deploying and Starting the Triton Server\n",
    "\n",
    "Before we deploy models to Triton Inference server, make sure to create a model_repository folder in the following structure:\n",
    "\n",
    "```\n",
    "gnn_model/ \n",
    "     1/ \n",
    "          gnn_model.onnx # ONNX model file for GNN \n",
    "     config.pbtxt # Triton configuration file for GNN model\n",
    "xgboost/ \n",
    "     1/ \n",
    "          xgboost.json # Model file for XGBoost (in JSON format) \n",
    "     config.pbtxt # Triton configuration file for XGBoost model\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "Explore more about Trition on GitHub repo [here](https://github.com/triton-inference-server)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5fd5c8d1-c807-4e00-bb41-64ce4732a691",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "40c23372-94aa-40fa-abe8-62b9d8b4c161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model repository directory. The name of this directory is arbitrary.\n",
    "REPO_PATH = os.path.abspath('model_repository')\n",
    "os.makedirs(REPO_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2452e1bb-9187-46f9-bccd-b1b0ce39dec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRITON_IMAGE = 'nvcr.io/nvidia/tritonserver:24.10-py3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26cf0957-8d69-46a3-b7e4-5457d82f9611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.10-py3: Pulling from nvidia/tritonserver\n",
      "Digest: sha256:48f5247728bbcf290bea0dbdf9ccc9d803f33fc472307167ce612ae9bab9b870\n",
      "Status: Image is up to date for nvcr.io/nvidia/tritonserver:24.10-py3\n",
      "nvcr.io/nvidia/tritonserver:24.10-py3\n"
     ]
    }
   ],
   "source": [
    "!docker pull {TRITON_IMAGE}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "698c62ce-3eea-405f-a2c1-c1791e7fa990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tritonserver\n",
      "tritonserver\n"
     ]
    }
   ],
   "source": [
    "!docker stop tritonserver\n",
    "!docker rm tritonserver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "213fa516-02db-4831-ba4b-bda224309d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61e77d2b258ec5b53342fcce049e82b1d6cc869d0de4ec79b60d8d4ca1a39209\n"
     ]
    }
   ],
   "source": [
    "!docker run --gpus all -d -p 8000:8000 -p 8001:8001 -p 8002:8002 -v {REPO_PATH}:/models --name tritonserver {TRITON_IMAGE} tritonserver --model-repository=/models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5b585d8b-13d2-40d4-9fcd-c4df519f9646",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tritonclient.grpc as triton_grpc\n",
    "import tritonclient.http as httpclient\n",
    "\n",
    "from tritonclient import utils as triton_utils\n",
    "HOST = 'localhost'\n",
    "PORT = 8000\n",
    "TIMEOUT = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0db1c383-f518-4b18-9b9c-0ecf3c3ad13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_grpc = triton_grpc.InferenceServerClient(url=f'{HOST}:{8001}')\n",
    "client_http = httpclient.InferenceServerClient(url=f'{HOST}:{PORT}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "23294e08-4eab-4d42-871c-e2124c1150f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for server to come online\n",
    "server_start = time.time()\n",
    "while True:\n",
    "    try:\n",
    "        if client_grpc.is_server_ready() or time.time() - server_start > TIMEOUT:\n",
    "            break\n",
    "    except triton_utils.InferenceServerException:\n",
    "        pass\n",
    "    time.sleep(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8bada1e0-d5b1-40c9-be6f-098de043a1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============================\n",
      "== Triton Inference Server ==\n",
      "=============================\n",
      "\n",
      "NVIDIA Release 24.10 (build 117849258)\n",
      "Triton Server Version 2.51.0\n",
      "\n",
      "Copyright (c) 2018-2024, NVIDIA CORPORATION & AFFILIATES.  All rights reserved.\n",
      "\n",
      "Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.\n",
      "\n",
      "This container image and its contents are governed by the NVIDIA Deep Learning Container License.\n",
      "By pulling and using the container, you accept the terms and conditions of this license:\n",
      "https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license\n",
      "\n",
      "WARNING: CUDA Minor Version Compatibility mode ENABLED.\n",
      "  Using driver version 555.58.02 which has support for CUDA 12.5.  This container\n",
      "  was built with CUDA 12.6 and will be run in Minor Version Compatibility mode.\n",
      "  CUDA Forward Compatibility is preferred over Minor Version Compatibility for use\n",
      "  with this container but was unavailable:\n",
      "  [[System has unsupported display driver / cuda driver combination (CUDA_ERROR_SYSTEM_DRIVER_MISMATCH) cuInit()=803]]\n",
      "  See https://docs.nvidia.com/deploy/cuda-compatibility/ for details.\n",
      "\n",
      "I1106 18:47:52.245303 1 pinned_memory_manager.cc:277] \"Pinned memory pool is created at '0x7f3696000000' with size 268435456\"\n",
      "I1106 18:47:52.250242 1 cuda_memory_manager.cc:107] \"CUDA memory pool is created on device 0 with size 67108864\"\n",
      "I1106 18:47:52.259821 1 model_lifecycle.cc:472] \"loading: model:1\"\n",
      "I1106 18:47:52.259884 1 model_lifecycle.cc:472] \"loading: xgboost:1\"\n",
      "I1106 18:47:52.263947 1 onnxruntime.cc:2875] \"TRITONBACKEND_Initialize: onnxruntime\"\n",
      "I1106 18:47:52.263976 1 onnxruntime.cc:2885] \"Triton TRITONBACKEND API version: 1.19\"\n",
      "I1106 18:47:52.263983 1 onnxruntime.cc:2891] \"'onnxruntime' TRITONBACKEND API version: 1.19\"\n",
      "I1106 18:47:52.263990 1 onnxruntime.cc:2921] \"backend configuration:\\n{\\\"cmdline\\\":{\\\"auto-complete-config\\\":\\\"true\\\",\\\"backend-directory\\\":\\\"/opt/tritonserver/backends\\\",\\\"min-compute-capability\\\":\\\"6.000000\\\",\\\"default-max-batch-size\\\":\\\"4\\\"}}\"\n",
      "I1106 18:47:52.287570 1 onnxruntime.cc:2986] \"TRITONBACKEND_ModelInitialize: model (version 1)\"\n",
      "I1106 18:47:52.288427 1 onnxruntime.cc:984] \"skipping model configuration auto-complete for 'model': inputs and outputs already specified\"\n",
      "I1106 18:47:52.290147 1 onnxruntime.cc:3051] \"TRITONBACKEND_ModelInstanceInitialize: model_0_0 (GPU device 0)\"\n",
      "I1106 18:47:52.290362 1 initialize.hpp:43] \"TRITONBACKEND_Initialize: fil\"\n",
      "I1106 18:47:52.290385 1 backend.hpp:47] \"Triton TRITONBACKEND API version: 1.19\"\n",
      "I1106 18:47:52.290397 1 backend.hpp:52] \"'fil' TRITONBACKEND API version: 1.19\"\n",
      "I1106 18:47:52.302457 1 model_initialize.hpp:37] \"TRITONBACKEND_ModelInitialize: xgboost (version 1)\"\n",
      "I1106 18:47:52.305042 1 instance_initialize.hpp:46] \"TRITONBACKEND_ModelInstanceInitialize: xgboost_0_0 (GPU device 0)\"\n",
      "\u001b[0;93m2024-11-06 18:47:52.396777734 [W:onnxruntime:, session_state.cc:1166 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.\u001b[m\n",
      "\u001b[0;93m2024-11-06 18:47:52.399780067 [W:onnxruntime:, session_state.cc:1168 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.\u001b[m\n",
      "I1106 18:47:52.455709 1 model_lifecycle.cc:839] \"successfully loaded 'xgboost'\"\n",
      "I1106 18:47:52.465784 1 model_lifecycle.cc:839] \"successfully loaded 'model'\"\n",
      "I1106 18:47:52.465857 1 server.cc:604] \n",
      "+------------------+------+\n",
      "| Repository Agent | Path |\n",
      "+------------------+------+\n",
      "+------------------+------+\n",
      "\n",
      "I1106 18:47:52.465948 1 server.cc:631] \n",
      "+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Backend     | Path                                                            | Config                                                                                                                                                        |\n",
      "+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {\"cmdline\":{\"auto-complete-config\":\"true\",\"backend-directory\":\"/opt/tritonserver/backends\",\"min-compute-capability\":\"6.000000\",\"default-max-batch-size\":\"4\"}} |\n",
      "| fil         | /opt/tritonserver/backends/fil/libtriton_fil.so                 | {\"cmdline\":{\"auto-complete-config\":\"true\",\"backend-directory\":\"/opt/tritonserver/backends\",\"min-compute-capability\":\"6.000000\",\"default-max-batch-size\":\"4\"}} |\n",
      "+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "I1106 18:47:52.466060 1 server.cc:674] \n",
      "+---------+---------+--------+\n",
      "| Model   | Version | Status |\n",
      "+---------+---------+--------+\n",
      "| model   | 1       | READY  |\n",
      "| xgboost | 1       | READY  |\n",
      "+---------+---------+--------+\n",
      "\n",
      "I1106 18:47:52.503081 1 metrics.cc:877] \"Collecting metrics for GPU 0: NVIDIA L40\"\n",
      "I1106 18:47:52.510717 1 metrics.cc:770] \"Collecting CPU metrics\"\n",
      "I1106 18:47:52.510886 1 tritonserver.cc:2598] \n",
      "+----------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Option                           | Value                                                                                                                                                                                                           |\n",
      "+----------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| server_id                        | triton                                                                                                                                                                                                          |\n",
      "| server_version                   | 2.51.0                                                                                                                                                                                                          |\n",
      "| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data parameters statistics trace logging |\n",
      "| model_repository_path[0]         | /models                                                                                                                                                                                                         |\n",
      "| model_control_mode               | MODE_NONE                                                                                                                                                                                                       |\n",
      "| strict_model_config              | 0                                                                                                                                                                                                               |\n",
      "| model_config_name                |                                                                                                                                                                                                                 |\n",
      "| rate_limit                       | OFF                                                                                                                                                                                                             |\n",
      "| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                                       |\n",
      "| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                                        |\n",
      "| min_supported_compute_capability | 6.0                                                                                                                                                                                                             |\n",
      "| strict_readiness                 | 1                                                                                                                                                                                                               |\n",
      "| exit_timeout                     | 30                                                                                                                                                                                                              |\n",
      "| cache_enabled                    | 0                                                                                                                                                                                                               |\n",
      "+----------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "I1106 18:47:52.513137 1 grpc_server.cc:2558] \"Started GRPCInferenceService at 0.0.0.0:8001\"\n",
      "I1106 18:47:52.513418 1 http_server.cc:4713] \"Started HTTPService at 0.0.0.0:8000\"\n",
      "I1106 18:47:52.555288 1 http_server.cc:362] \"Started Metrics Service at 0.0.0.0:8002\"\n"
     ]
    }
   ],
   "source": [
    "!docker logs tritonserver\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fe7482-8b02-484e-aee7-4bce8e01045c",
   "metadata": {},
   "source": [
    "## Loading and Preprocessing Test Data\n",
    "\n",
    "We are loading the test dataset created in the data preprocessing notebook, applying transformations using the preprocessor.pkl file, and passing the test dataset to the GNN ONNX model deployed in Triton for node embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "58ffb4bc-e0f6-4db9-8ee5-fd17af79fe0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amount</th>\n",
       "      <th>Errors</th>\n",
       "      <th>Card</th>\n",
       "      <th>Chip</th>\n",
       "      <th>City</th>\n",
       "      <th>Zip</th>\n",
       "      <th>MCC</th>\n",
       "      <th>Merchant</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>488.00</td>\n",
       "      <td>XX</td>\n",
       "      <td>6149</td>\n",
       "      <td>Chip Transaction</td>\n",
       "      <td>Rome</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3684</td>\n",
       "      <td>-7807051024009846392</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.22</td>\n",
       "      <td>XX</td>\n",
       "      <td>6149</td>\n",
       "      <td>Chip Transaction</td>\n",
       "      <td>Rome</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5311</td>\n",
       "      <td>9057735476014445185</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.79</td>\n",
       "      <td>XX</td>\n",
       "      <td>6149</td>\n",
       "      <td>Chip Transaction</td>\n",
       "      <td>Rome</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4214</td>\n",
       "      <td>6098563624419731578</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.27</td>\n",
       "      <td>XX</td>\n",
       "      <td>6149</td>\n",
       "      <td>Chip Transaction</td>\n",
       "      <td>Rome</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5812</td>\n",
       "      <td>7069584154815291371</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38.63</td>\n",
       "      <td>XX</td>\n",
       "      <td>6149</td>\n",
       "      <td>Chip Transaction</td>\n",
       "      <td>Rome</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5921</td>\n",
       "      <td>3017176960763408508</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Amount Errors  Card              Chip  City  Zip   MCC  \\\n",
       "0  488.00     XX  6149  Chip Transaction  Rome  0.0  3684   \n",
       "1   14.22     XX  6149  Chip Transaction  Rome  0.0  5311   \n",
       "2   13.79     XX  6149  Chip Transaction  Rome  0.0  4214   \n",
       "3   12.27     XX  6149  Chip Transaction  Rome  0.0  5812   \n",
       "4   38.63     XX  6149  Chip Transaction  Rome  0.0  5921   \n",
       "\n",
       "              Merchant  Fraud  \n",
       "0 -7807051024009846392      1  \n",
       "1  9057735476014445185      1  \n",
       "2  6098563624419731578      1  \n",
       "3  7069584154815291371      1  \n",
       "4  3017176960763408508      1  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read untransformed data\n",
    "dataset_base_path = '../data/TabFormer'\n",
    "pd.set_option('future.no_silent_downcasting', True)    \n",
    "untransformed_df = pd.read_csv('../data/TabFormer/xgb/untransformed_test.csv')\n",
    "untransformed_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8d4fbad5-b7c0-4f21-8028-cf25f2f40092",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(dataset_base_path, 'preprocessor.pkl'),'rb') as f:\n",
    "    loaded_transformer = pickle.load(f)\n",
    "    transformed_data = loaded_transformer.transform(untransformed_df.loc[:, untransformed_df.columns[:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fdb9a923-1eed-4705-ab4b-89124da0d6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Convert data to torch tensors\n",
    "X = torch.tensor(transformed_data).to(torch.float32).to(device)\n",
    "y = torch.tensor(untransformed_df[untransformed_df.columns[-1]].values ).to(torch.long).to(device)\n",
    "edge_index = torch.tensor([[], []], dtype=torch.int64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8645ebf6-6d74-481d-9386-0254c67ee521",
   "metadata": {},
   "source": [
    "## Submitting inference requests to models deployed in Triton\n",
    "\n",
    "- Create inputs for the ONNX model.\n",
    "- Send an inference request to the ONNX model.\n",
    "- Send the output of the ONNX model as an input to the XGBoost model for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6143a092-8824-4fdc-afc0-ef9443e2a218",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting data to numpy format for inference\n",
    "X_numpy = X.detach().cpu().numpy()  # Converting to NumPy if it's a PyTorch tensor\n",
    "edge_index_numpy = edge_index.detach().cpu().numpy() \n",
    "\n",
    "inputs_features = httpclient.InferInput(\"l_x_\", X_numpy.shape, datatype=\"FP32\")\n",
    "inputs_features.set_data_from_numpy(X_numpy)\n",
    "\n",
    "inputs_edges = httpclient.InferInput(\"l_edge_index_\", edge_index_numpy.shape, datatype=\"INT64\")\n",
    "inputs_edges.set_data_from_numpy(edge_index_numpy)\n",
    "\n",
    "outputs = httpclient.InferRequestedOutput(\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6fb62e91-9cb8-43bd-b267-400f43e1dd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Querying the server\n",
    "results = client_http.infer(model_name=\"model\", inputs=[inputs_features, inputs_edges], outputs=[outputs])\n",
    "node_embeddings = results.as_numpy('output')\n",
    "# print(node_embeddings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cc567a66-73d0-4650-bbce-4d47627c72b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_xgboost = httpclient.InferInput(\"input__0\", node_embeddings.shape, datatype=\"FP32\")\n",
    "inputs_xgboost.set_data_from_numpy(node_embeddings)\n",
    "\n",
    "outputs_xgboost = httpclient.InferRequestedOutput(\"output__0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "29582cba-0b79-42c8-959c-ad93564bcaa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3322781  0.499941   0.47168913 ... 0.01088735 0.87886477 0.01088735]\n",
      "tensor([1, 1, 1,  ..., 0, 0, 0], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "results = client_http.infer(model_name=\"xgboost\", inputs=[inputs_xgboost], outputs=[outputs_xgboost])\n",
    "predictions = results.as_numpy('output__0')\n",
    "\n",
    "print(predictions)\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "841e918a-3846-475c-a20f-ce952a0c24d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of XGBoost model trained on node embeddings\n",
      "Accuracy: 0.8766\n",
      "Precision: 0.2643\n",
      "Recall: 0.2928\n",
      "F1 Score: 0.2778\n",
      "Confusion Matrix: [[21956  1701]\n",
      " [ 1476   611]]\n"
     ]
    }
   ],
   "source": [
    "from cuml.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import cupy as cp\n",
    "from torch.utils.dlpack import to_dlpack\n",
    "\n",
    "labels = y\n",
    "pred_labels = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Move labels to CPU for evaluation\n",
    "labels_cpu = labels.cpu().numpy()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "accuracy = accuracy_score(labels_cpu, pred_labels)\n",
    "precision = precision_score(labels_cpu, pred_labels, zero_division=0)\n",
    "recall = recall_score(labels_cpu, pred_labels, zero_division=0)\n",
    "f1 = f1_score(labels_cpu, pred_labels, zero_division=0)\n",
    "\n",
    "print(f\"Performance of XGBoost model trained on node embeddings\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "conf_mat = confusion_matrix(labels.cpu().numpy(), pred_labels)\n",
    "print('Confusion Matrix:', conf_mat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
